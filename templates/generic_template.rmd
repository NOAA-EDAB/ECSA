---
title:
    | 
    | Ecosystem Context for Stock Assessments:
    | {{STOCK_SUBAREA}}{{COMMON_NAME}}
date: "`r format(Sys.time(), '%B %d, %Y')`"
always_allow_html: yes
site: "bookdown::bookdown_site"
output:
  bookdown::gitbook:
    lib_dir: "book_assets"
    config:
      toc:
        collapse: none
        after: |
          <li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>
---

```{r, include = FALSE}
## Load packages
# library(ecsa)
library(dplyr)
library(ggplot2)
library(plotly)
library(DT)
library(jpeg)
library(patchwork)
library(ggthemes)
library(AICcmodavg)
library(stringr)
library(ecotrend)
library(magrittr)
library(raster)
library(stars)
library(dplyr)
library(here)
library(gt)

knitr::opts_chunk$set(echo = F, message = F ,warning = F, fig.align = 'center')

## Read in stock area vectors

all_stock_season <- readr::read_csv(here::here("data/stock_data/stock_list.csv"),
                                 col_types = readr::cols(
                                   common_name = readr::col_character(),
                                   sci_name = readr::col_character(),
                                   cc_name = readr::col_character(),
                                   stock_name = readr::col_character(),
                                   species_code = readr::col_character(),
                                   svspp = readr::col_double(),
                                   stock_season = readr::col_character(),
                                   strata = readr::col_double()
                                 ))

## Put all mustaches here
common_name <- "{{COMMON_NAME}}"
stock_code <- "{{SPECIES_CODE}}"
stock_name <- "{{STOCK_NAME}}"
cc_name <- "{{CC_NAME}}"
stock_subarea <- "{{STOCK_SUBAREA}}"
# svspp <- "{{SVSPP}}"


source(here::here("R/map_strata.R"))
source(here::here("R/get_strata.R"))
source(here::here("R/crop_to_strata.R"))
source(here::here("R/stars_to_series.R"))
source(here::here("R/tab_plotly.R"))
source(here::here("R/create_buttons.R"))
source(here::here("R/STARS_v18.R"))
source(here::here("R/gls_summary.R"))


#Function to rank time series by group mean. Returns top N groups
rank_by_group <- function(df, group, N, join_with){
  out <- df %>% 
    dplyr::group_by(Grouping = get(group)) %>% 
    dplyr::summarise(M = mean(Mean, na.rm = T)) %>% 
    top_n(N) %>% 
    arrange(desc(M)) %>% 
    mutate(id = 1:N) 
  return(out)
}

N <- 5
alpha <- 0.05

strata <- all_stock_season %>%   
  dplyr::filter(stock_name == !!stock_name)

stock_season <- strata %>% pull(stock_season) %>% unique()

```


# Overview 

### Introduction
This report provides contextual ecosystem information for {{STOCK_SUBAREA}}{{COMMON_NAME}} (*{{SCI_NAME}}*) on the Northeast U.S. Continental Shelf. Data extractions for spring and fall are confined to the {{COMMON_NAME}} stock area based on respective survey strata sets. The information is intended to span a range of potential factors affecting the productivity and distribution of {{COMMON_NAME}}, including: surface and bottom temperature and salinity, chlorophyll concentrations, indices of habitat, diet composition, and abundance of key zooplankton prey of larval {{COMMON_NAME}}. These factors can be used to qualitatively inform the interpretation of population status and/or quantitatively to improve model responsiveness to ecosystem factors. The range and complexity of ecosystem data makes it unlikely to find the most relevant and comprehensive factor variables with a first evaluation; this process will require an iterative approach of evaluation and feedback. Additional indices can be included to address the needs of the working group.

#### Summary

* Add summary point 
* Add summary point 
* Add summary point 

### Strata definition
```{r strata-map, eval = T, echo = FALSE, fig.cap= "Strata map for {{COMMON_NAME}} (*{{SCI_NAME}}*) on the NE shelf", message = FALSE, warning = FALSE, fig.align='center'}
map_strata(stock_name = stock_name,
           common_name = common_name,
           stock_season = stock_season,
           strata = strata,
           overwrite = FALSE,
           save_plot = FALSE)
```


#### A note on data flow:

Data sets in the template `Rmarkdown` file for this document are first passed to the `stars_to_series` function. This function takes stacks of raster layers and crops them into the shape of the seasonal stock area. If the first guess at the seasonal stock area (passed through the title of the `.rdata` file) fails, the function returns environmental information in the available stock area for the opposing season. 

Therefore, if a spring data set is provided, but only a fall stock area is available, then the spring data is returned for the fall stock area. A third seasonal designation exists in the data ("both"). In this case, the environmental information is provided for combined spring and fall stock areas.

_Last updated on `r format(Sys.Date(), format = "%B %e %Y")`._

# Temperature

An optimal interpolation procedure was used to estimate NE Shelf surface and bottom temperatures for two seasonal time frames (see [methods](https://noaa-edab.github.io/ECSA/#sec:methodstempsalin)). The temperature estimates were standardized to April 3 and October 11 for spring and fall over the period 1968-2018. Surface and bottom temperature within the `r common_name` stock areas are shown below.

## Bottom Temperature

```{r bot_temp_process}
spring_bottom_temp <- 
  stars_to_series(r = "bot_temp_spring_spdf.rdata",
                stock_name = stock_name, 
                common_name = common_name,
                stock_season = stock_season,
                data_season = "spring",
                measure_name = "bottom_temp") %>% 
  mutate(season = "Spring") %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T) 

STARS_in <- spring_bottom_temp$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (spring_bottom_temp$`selection summary`$pval[1] < 0.05){
  spring_bottom_temp <- spring_bottom_temp$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    spring_bottom_temp <- spring_bottom_temp$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}

spring_bottom_temp %<>%  
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

spring_min <- min(spring_bottom_temp$Time)

fall_bottom_temp <- 
  stars_to_series(r = "bot_temp_fall_spdf.rdata",
               stock_name = stock_name,
               common_name = common_name,
               stock_season = stock_season,
               data_season = "fall",
                measure_name = "bottom_temp") %>% 
  mutate(season = "fall") %>% 
  dplyr::distinct() %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T) 

STARS_in <- fall_bottom_temp$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (fall_bottom_temp$`selection summary`$pval[1] < 0.05){
  fall_bottom_temp <- fall_bottom_temp$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    fall_bottom_temp <- fall_bottom_temp$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}


fall_bottom_temp %<>%
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

fall_min <- min(fall_bottom_temp$Time)

if (fall_min > spring_min) {
  plot_min <- spring_min
} else {
  plot_min <- fall_min
}
```

```{r bot_temp_fall_plt, fig.height=3}
fall_bottom_temp_plt <- 
  tab_plotly(fall_bottom_temp, series.name = "Temperature") %>% 
  layout(title = "Fall",
         yaxis = list(title = "Temperature (&deg;C)",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(fall_bottom_temp$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))

fall_bottom_temp_plt
```


```{r bot_temp_spring_plt, fig.height=3}
spring_bottom_temp_plt <- 
  tab_plotly(spring_bottom_temp, series.name = "Temperature") %>% 
  layout(title = "Spring",
         yaxis = list(title = "Temperature (&deg;C)",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(spring_bottom_temp$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))

spring_bottom_temp_plt
```

## Surface Temperature

```{r surf_temp_process}
spring_surface_temp <- 
  stars_to_series(r = "surf_temp_spring_spdf.rdata",
                stock_name = stock_name,
                common_name = common_name,
                stock_season = stock_season,
                data_season = "spring",
                measure_name = "surface_temp") %>% 
  mutate(season = "Spring") %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T) 

STARS_in <- spring_surface_temp$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (spring_surface_temp$`selection summary`$pval[1] < 0.05){
  spring_surface_temp <- spring_surface_temp$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    spring_surface_temp <- spring_surface_temp$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}

spring_surface_temp %<>%  
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

spring_min <- min(spring_surface_temp$Time)

fall_surface_temp <- 
  stars_to_series(r = "surf_temp_fall_spdf.rdata",
                stock_name = stock_name,
                common_name = common_name,
                stock_season = stock_season,
                data_season = "fall",
                measure_name = "surface_temp") %>% 
  mutate(season = "fall") %>% 
  dplyr::distinct() %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T) 

STARS_in <- fall_surface_temp$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (fall_surface_temp$`selection summary`$pval[1] < 0.05){
  fall_surface_temp <- fall_surface_temp$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    fall_surface_temp <- fall_surface_temp$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}


fall_surface_temp %<>%
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

fall_min <- min(fall_surface_temp$Time)

if (fall_min > spring_min) {
  plot_min <- spring_min
} else {
  plot_min <- fall_min
}
```

```{r surf_temp_fall_plt, fig.height=3}
fall_surface_temp_plt <- 
  tab_plotly(fall_surface_temp, series.name = "Temperature") %>% 
  layout(title = "Fall",
         yaxis = list(title = "Temperature (&deg;C)",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(fall_surface_temp$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))

fall_surface_temp_plt
```


```{r surf_temp_spring_plt, fig.height=3}
spring_surface_temp_plt <- 
  tab_plotly(spring_surface_temp, series.name = "Temperature") %>% 
  layout(title = "Spring",
         yaxis = list(title = "Temperature (&deg;C)",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(spring_surface_temp$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))

spring_surface_temp_plt
```

# Salinity

An optimal interpolation procedure was used to estimate NE Shelf surface and bottom salinity for two seasonal time frames (see [methods](https://noaa-edab.github.io/ECSA/#sec:methodstempsalin)). Though collected with temperature data, reliable instrumentation limits this time series to 1992-2018. The salinity estimates were standardized to April 3 and October 11 for spring and fall. Surface and bottom salinities within the `r common_name` stock areas are shown below.

## Bottom Salinity

```{r bot_sal_process}
spring_bottom_sal <- 
  stars_to_series(r = "bot_sal_spring_spdf.rdata",
                stock_name = stock_name, 
                common_name = common_name, 
                stock_season = stock_season,
                data_season = "spring",
                measure_name = "bottom_sal") %>% 
  mutate(season = "Spring") %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T) 

STARS_in <- spring_bottom_sal$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (spring_bottom_sal$`selection summary`$pval[1] < 0.05){
  spring_bottom_sal <- spring_bottom_sal$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    spring_bottom_sal <- spring_bottom_sal$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}

spring_bottom_sal %<>%
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

spring_min <- min(spring_bottom_sal$Time)

fall_bottom_sal <- 
  stars_to_series(r = "bot_sal_fall_spdf.rdata",
               stock_name = stock_name, 
               common_name = common_name, 
               stock_season = stock_season,
               data_season = "fall",
                measure_name = "bottom_sal") %>% 
  mutate(season = "fall") %>% 
  dplyr::distinct() %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T) 

STARS_in <- fall_bottom_sal$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (fall_bottom_sal$`selection summary`$pval[1] < 0.05){
  fall_bottom_sal <- fall_bottom_sal$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    fall_bottom_sal <- fall_bottom_sal$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}

fall_bottom_sal %<>%
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

fall_min <- min(fall_bottom_sal$Time)

if (fall_min > spring_min) {
  plot_min <- spring_min
} else {
  plot_min <- fall_min
}
```

```{r bot_sal_fall_plt, fig.height=3}
fall_bottom_sal_plt <- 
  tab_plotly(fall_bottom_sal, series.name = "Salinity") %>% 
  layout(title = "Fall",
         yaxis = list(title = "Salinity (PSU)",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(fall_bottom_sal$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))

fall_bottom_sal_plt
```


```{r bot_sal_spring_plt, fig.height=3}
spring_bottom_sal_plt <- 
  tab_plotly(spring_bottom_sal, series.name = "Salinity") %>% 
  layout(title = "Spring",
         yaxis = list(title = "Salinity (PSU)",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(spring_bottom_sal$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))

spring_bottom_sal_plt
```

## Surface Salinity

```{r surf_sal_process}
spring_surface_sal <- 
  stars_to_series(r = "surf_sal_spring_spdf.rdata",
                stock_name = stock_name, 
                common_name = common_name, 
                stock_season = stock_season,
                data_season = "spring",
                measure_name = "surface_sal") %>% 
  mutate(season = "Spring") %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T) 

STARS_in <- spring_surface_sal$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (spring_surface_sal$`selection summary`$pval[1] < 0.05){
  spring_surface_sal <- spring_surface_sal$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    spring_surface_sal <- spring_surface_sal$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}

spring_surface_sal %<>%
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

spring_min <- min(spring_surface_sal$Time)

fall_surface_sal <- 
  stars_to_series(r = "surf_sal_fall_spdf.rdata",
                stock_name = stock_name, 
                common_name = common_name, 
                stock_season = stock_season,
                data_season = "fall",
                measure_name = "surface_sal") %>% 
  mutate(season = "fall") %>% 
  dplyr::distinct() %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T) 

STARS_in <- fall_surface_sal$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (fall_surface_sal$`selection summary`$pval[1] < 0.05){
  fall_surface_sal <- fall_surface_sal$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    fall_surface_sal <- fall_surface_sal$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}

fall_surface_sal %<>%
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

fall_min <- min(fall_surface_sal$Time)

if (fall_min > spring_min) {
  plot_min <- spring_min
} else {
  plot_min <- fall_min
}
```

```{r surf_sal_fall_plt, fig.height=3}
fall_surface_sal_plt <- 
  tab_plotly(fall_surface_sal, series.name = "Salinity") %>% 
  layout(title = "Fall",
         yaxis = list(title = "Salinity (PSU)",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(fall_surface_sal$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))

fall_surface_sal_plt
```


```{r surf_sal_spring_plt, fig.height=3}
spring_surface_sal_plt <- 
  tab_plotly(spring_surface_sal, series.name = "Salinity") %>% 
  layout(title = "Spring",
         yaxis = list(title = "Salinity (PSU)",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(spring_surface_sal$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))

spring_surface_sal_plt
```

# Habitat and abundance

## Occurrence probability

The probability of occurrence was estimated using random forest classification models (see [methods](https://noaa-edab.github.io/ECSA/#sec:methodsocc)). Probabilities were extracted for the spring and fall stock definition areas. 

```{r occ_prob, fig.height=4}
spring_occ_prob <- 
  stars_to_series(r = "occurrence_prob_spring.rdata",
                stock_name = stock_name, 
                common_name = common_name, 
                stock_season = stock_season,
                data_season = "spring",
                measure_name = "occurrence") %>% 
  dplyr::select(Spring = Mean,
                Time)

fall_occ_prob <- 
  stars_to_series(r = "occurrence_prob_fall.rdata",
                stock_name = stock_name, 
                common_name = common_name, 
                stock_season = stock_season,
                data_season = "fall",
                measure_name = "occurrence") %>% 
  dplyr::select(Fall = Mean,
                Time)

occ_prob <- spring_occ_prob %>% 
  left_join(.,fall_occ_prob, by  = "Time") %>% 
  dplyr::select(Time, Spring, Fall)

occ_prob_plt <- occ_prob %>% 
  tab_plotly(.) %>% 
  layout(title = "Occupancy Probability", 
         yaxis = list(title = "Occupancy probability",
                      hoverformat = '.3f'))

occ_prob_plt
```

## Biomass

```{r biomass_processing}
spring_biomass <- 
  stars_to_series(r = "biomass_spring.rdata",
                stock_name = stock_name, 
                common_name = common_name, 
                stock_season = stock_season,
                data_season = "spring",
                measure_name = "biomass") %>% 
  mutate(season = "Spring") %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T) 

STARS_in <- spring_biomass$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (spring_biomass$`selection summary`$pval[1] < 0.05){
  spring_biomass <- spring_biomass$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    spring_biomass <- spring_biomass$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}

spring_biomass %<>%
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

spring_min <- min(spring_biomass$Time)

fall_biomass <- 
  stars_to_series(r = "biomass_fall.rdata",
              stock_name = stock_name, 
              common_name = common_name, 
              stock_season = stock_season,
              data_season = "fall",
                measure_name = "biomass") %>% 
  mutate(season = "fall") %>% 
  dplyr::distinct() %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T) 

STARS_in <- fall_biomass$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (fall_biomass$`selection summary`$pval[1] < 0.05){
  fall_biomass <- fall_biomass$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    fall_biomass <- fall_biomass$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}

fall_biomass %<>%
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

fall_min <- min(fall_biomass$Time)

if (fall_min > spring_min) {
  plot_min <- spring_min
} else {
  plot_min <- fall_min
}
```


```{r fall_biomass_plt, fig.height=3}
fall_biomass_plt <- 
  tab_plotly(fall_biomass, series.name = "Biomass") %>% 
  layout(title = "Fall",
         yaxis = list(title = "Value",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(fall_biomass$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))

fall_biomass_plt
```


```{r spring_biomass_plt, fig.height=3}
spring_biomass_plt <-  
  tab_plotly(spring_biomass, series.name = "Biomass") %>% 
  layout(title = "Spring",
         yaxis = list(title = "Value",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(spring_biomass$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))

spring_biomass_plt
```


# Chlorophyll

The concentration of chlorophyll was measured with a suite of satellite sensors and merged into a single dataset (see [methods](https://noaa-edab.github.io/ECSA/#sec:methodschl)). Chlorophyll concentrations in the spring and fall `r common_name` stock areas are shown below.


```{r chl_processing}
spring_chl <- 
stars_to_series(r = "chlorophyll_conc.rdata",
              stock_name = stock_name, 
              common_name = common_name, 
              stock_season = stock_season,
              data_season = "spring",
                measure_name = "biomass",
                process_to_season = "spring")$spring %>% 
  mutate(season = "Spring") %>% 
    dplyr::distinct() %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T)

STARS_in <- spring_chl$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (spring_chl$`selection summary`$pval[1] < 0.05){
  spring_chl <- spring_chl$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    spring_chl <- spring_chl$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}

spring_chl %<>%
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

spring_min <- min(spring_chl$Time)

fall_chl <- 
stars_to_series(r = "chlorophyll_conc.rdata",
                stock_name = stock_name, 
                common_name = common_name, 
                stock_season = stock_season,
                data_season = "fall",
                measure_name = "biomass",
                process_to_season = "fall")$fall %>% 
  mutate(season = "fall") %>% 
    dplyr::distinct() %>% 
  ecotrend::glsMs(Mean ~ Time,
                data = .,
                diagnostic = T,
                fit_model  = T)

STARS_in <- fall_chl$fit %>% 
  dplyr::select(-fit) %>% 
  as.matrix()

if (fall_chl$`selection summary`$pval[1] < 0.05){
  fall_chl <- fall_chl$fit %>% 
      dplyr::select(Time = time, 
                Series = series,
                Trend = fit)
} else {
    fall_chl <- fall_chl$fit %>% 
      dplyr::select(Time = time, 
                Series = series)
}

fall_chl %<>%
  left_join(.,STARS(mat.in = STARS_in),by = "Time") %>% 
  dplyr::select(-Data, -RSI, -Regime.Number) %>% 
  dplyr::select(which(sapply(.,var)!=0))

fall_min <- min(fall_chl$Time)



if (fall_min > spring_min) {
  plot_min <- spring_min
} else {
  plot_min <- fall_min
}
```

```{r fall_chl_plt, fig.height=3}
fall_chl_plt <- 
  tab_plotly(fall_chl, series.name = "CHL") %>% 
  layout(title = "Fall",
         yaxis = list(title = "Chlorophyll (mg m<sup>-3</sup>)",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(fall_chl$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))

fall_chl_plt
```

```{r spring_chl_plt, fig.height=3}
spring_chl_plt <- 
  tab_plotly(spring_chl, series.name = "CHL") %>% 
  layout(title = "Spring",
         yaxis = list(title = "Chlorophyll (mg m<sup>-3</sup>)",
                      hoverformat = '.3f'),
         xaxis = list(range = c(plot_min, max(spring_chl$Time)),
                      title = ""),
         showlegend = T, legend = list(orientation = 'h'))
spring_chl_plt 
```


# Zooplankton

## Annual 

```{r zoo_1yr_spring, fig.height=4}
spring_zoo_1yr <- stars_to_series(r <- "zoo_spring_rasters_1yr.rdata",
                stock_name = stock_name, 
                common_name = common_name, 
                stock_season = stock_season,
                data_season = "spring",
                measure_name = "zoo",
                group_regex = "[^A-Z_](.*)(?=_)") %>% 
  mutate(season = "spring") %>% 
  left_join(rank_by_group(., group = "Grouping", N = N),
            by = "Grouping") %>% 
  dplyr::filter(!is.na(id)) %>% 
  arrange(id) %>% 
  dplyr::rename(Genera = Grouping) %>% 
  dplyr::select(-id, -M, -season) %>%
  tidyr::spread(Genera, Mean)

buttons <- create_buttons(spring_zoo_1yr)

spring_zoo_1yr_plt <-
tab_plotly(spring_zoo_1yr) %>% 
  layout(title = "Spring zooplankton abundance",
         yaxis = list(title = "Abundance (log num m<sup>-3</sup>)",
                      hoverformat = '.3f'),
         showlegend = F, 
         updatemenus = buttons)

spring_zoo_1yr_plt
```


```{r zoo_1yr_fall, fig.height=4}
fall_zoo_1yr <- stars_to_series(r <- "zoo_fall_rasters_1yr.rdata",
               stock_name = stock_name, 
               common_name = common_name, 
               stock_season = stock_season,
               data_season = "fall",
                measure_name = "zoo",
                group_regex = "[^A-Z_](.*)(?=_)") %>% 
  mutate(season = "fall") %>% 
  left_join(rank_by_group(., group = "Grouping", N = N),
            by = "Grouping") %>% 
  dplyr::filter(!is.na(id)) %>% 
  arrange(id) %>% 
  dplyr::rename(Genera = Grouping) %>% 
  dplyr::select(-id, -M, -season) %>%
  tidyr::spread(Genera, Mean)

buttons <- create_buttons(fall_zoo_1yr)

fall_zoo_1yr_plt <-
tab_plotly(fall_zoo_1yr) %>% 
  layout(title = "Fall zooplankton abundance",
         yaxis = list(title = "Abundance (log num m<sup>-3</sup>)",
                      hoverformat = '.3f'),
         showlegend = F, 
         updatemenus = buttons)

fall_zoo_1yr_plt
```

## 5 year rolling mean

```{r zoo_5yr_spring, fig.height=4}
spring_zoo_5yr <- stars_to_series(r <- "zoo_spring_rasters_5yr.rdata",
                stock_name = stock_name, 
                common_name = common_name, 
                stock_season = stock_season,
                data_season = "spring",
                measure_name = "zoo",
                group_regex = "[^A-Z_](.*)(?=_)") %>% 
  mutate(season = "spring") %>% 
  left_join(rank_by_group(., group = "Grouping", N = N),
            by = "Grouping") %>% 
  dplyr::filter(!is.na(id)) %>% 
  arrange(id) %>% 
  dplyr::rename(Genera = Grouping) %>% 
  dplyr::select(-id, -M, -season) %>%
  tidyr::spread(Genera, Mean)

buttons <- create_buttons(spring_zoo_5yr)

spring_zoo_5yr_plt <-
tab_plotly(spring_zoo_5yr) %>% 
  layout(title = "Spring zooplankton abundance",
         yaxis = list(title = "Abundance (log num m<sup>-3</sup>)",
                      hoverformat = '.3f'),
         showlegend = F, 
         updatemenus = buttons)

spring_zoo_5yr_plt
```


```{r zoo_5yr_fall, fig.height=4}
fall_zoo_5yr <- stars_to_series(r <- "zoo_fall_rasters_5yr.rdata",
                stock_name = stock_name, 
                common_name = common_name, 
                stock_season = stock_season,
                measure_name = "zoo",
                data_season = "fall",
                group_regex = "[^A-Z_](.*)(?=_)") %>% 
  mutate(season = "fall") %>% 
  left_join(rank_by_group(., group = "Grouping", N = N),
            by = "Grouping") %>% 
  dplyr::filter(!is.na(id)) %>% 
  arrange(id) %>% 
  dplyr::rename(Genera = Grouping) %>% 
  dplyr::select(-id, -M, -season) %>%
  tidyr::spread(Genera, Mean)

buttons <- create_buttons(fall_zoo_5yr)

fall_zoo_5yr_plt <-
tab_plotly(fall_zoo_1yr) %>% 
  layout(title = "Fall zooplankton abundance",
         yaxis = list(title = "Abundance (log num m<sup>-3</sup>)",
                      hoverformat = '.3f'),
         showlegend = F,
         updatemenus = buttons)

fall_zoo_5yr_plt
```




# Methods {#methods}

## Surface and Bottom Temperature and Salinity {#sec:methodstempsalin}

### Study System
The U.S. Northeast Shelf ecosystem, which roughly aligns with the boundaries of the Northeast U.S. Continental Shelf Large Marine Ecosystem (LME), is the study area for the surface and bottom thermal environments. Surface and bottom temperatures were estimated over a 0.1° latitude/longitude grid, termed the estimation grid, which circumscribes the range of ecosystem assessment areas in the [region](#fig:study-area). The difference between the extents of the estimation grid from the extent of the LME relate to the resource management programs that are the sources of the data, which are focused on fishery management needs in the region. 

### Data Source
Temperature and salinity were collected on the Northeast Shelf as part of ongoing resource and ecosystem surveys conducted by the Northeast Fisheries Science Center. Water column temperatures have been collected contemporaneously to trawl tows associated with a bottom trawl survey beginning in the fall of 1963 and five years later during spring [@Despres1988]. In addition, the ecosystem has been surveyed by multiple sampling programs with varying sampling designs. The two most comprehensive monitoring programs over the study period were the MARMAP (1977-1987) and the Ecosystem Monitoring Program or EcoMon (1992-present) programs, both serving as shelf-wide surveys of the ecosystem [@Sherman1998; @Kane2007]. Temperature measurements were made with a mix of Conductivity Temperature and Depth (CTD) instruments, analog XBT, digital XBT, mechanical BT, glass thermometers (bottle temps) and trawl mounted temperature loggers instruments collecting either water column profiles or temperatures  measured at targeted depths. Salinity measurements used in this analysis was limited to 1992-2017 when CTD instrument were used. Surface and bottom temperatures were identified from these measurements. Temperatures representing the spring period include data collected during the months of February to June; however, 99% of the samples were collected during the months of March to May. Likewise, the fall period samples include data collected during September to December, with 99% of the samples collected during September to November. The total number of surface temperature measurements were 14,540 and 14,666 for spring and fall, respectively; and, 14,450 and 14,656 for spring and fall bottom temperature, respectively. On average, there were 290 temperature measurements by season, depth, and year. The number of salinity observation per year were similar.

### Interpolation Procedure
Seasonal surface and bottom temperature fields were estimated using an optimal interpolation approach. The optimal interpolation combined a climatological depiction of temperature and an annual estimates based on the data for a particular depth and season. (There were a number of precursor steps that are described below.). 
The surveys used to collect the data were conducted during the same period each year, however, there was variation in survey timing. To account for this, temperatures were standardized to a collection date of April 3 for spring surveys and October 11 for fall using linear regression for each depth and season over the sample grid (see Appendix, [Figure A1](#fig:doc_correction)). For each depth and season, annual shelf-wide mean temperatures were calculated using the data from sample grid locations with at least 80% of the time series present. The annual observations were then transformed to anomalies by subtracting the appropriate annual mean. All anomalies for a season and depth were combined over years into a single anomaly field or climatology. 

The annual estimate of temperature for a depth and season was imputed by used universal kriging to estimate the temperature over the estimation grid with depth as a covariate. The kriging yielded temperature estimates and a variance estimate over the same grid. The optimal interpolation field was assembled by combining the annual estimate and information from the anomaly climatology. The climatology was re-leveled from anomaly values to temperatures by adding back the appropriate annual mean. For each location in the estimation grid, temperature was calculated as a weighted mean between the kriged annual estimate and the releveled climatology. The weightings in the calculations were partitioned based on the variance field of the annual kriging. The field was divided into quartiles from low to high variance with the weighting ratio of annual:climatology temperatures of 4:1, 3:1, 2:1, and 1:1, respectively. Hence, in areas of low variance the weighted mean was based on a weighting of 4:1, which would reflect a higher contribution of information from the annual estimate and thus be closer to an observation. In areas with high variance, the weighting ratio of 1:1 would reflect a greater effect of the climatology in determining the interpolation estimate. 

The optimal interpolation temperature fields were evaluated using cross validation and a comparison to external data. The performance of optimal interpolation was compared to the predictive skill of using either the climatology or annual interpolation alone by doing ten random cross validations of each treatment. Each random draw of training and test sets sampled 3% of the data for the test set, or about 500 observations per draw. The temperature fields were fit with the training data and compared with the test set data. The lowest error rates were realized with the optimal interpolation contrasted with highest predictive error associated with fields based on the climatology alone (see Appendix, [Figure A2](#fig:cross_val)). The spatial distribution of error had distinct depth and seasonal patterns. The spatial errors associated with the surface estimates were generally low with the exception of a few locations along the shelf break between latitudes 39-41°N; the spatial error in the bottom temperature varied by season, and was concentrated along the shelf break in spring and across the shelf between latitudes 36-40°N in fall (see Appendix, [Figure A3](#fig:oi_mae)). The optimal interpolation data were also compared to external data from other collection programs. The absolute errors between surface temperature data collected by satellites and the interpolation had interquartile ranges of approximately ±0.75°C (see Appendix, [Figure A4](#fig:oi_compare)). The absolute error in a comparison of interpolated bottom temperature to opportunist sampling was approximately ±0.75°C for spring bottom temperature and approximately 0.75-1.0°C in the fall. Salinity was estimated in the same way with the exception of collection correction, which was deemed unnecessary for the salinity data.

### {#fig:study-area}

```{r study area, echo = F, fig.align="center", fig.cap = "Map of the study system with half-degree sample grid (blue lines) and extent of estimation grid shown in beige points (a). Major features of the study system with shelf break marked in purple line (b). 100m depth shown as dashed line."}
knitr::include_graphics('data/images/ECSA_study_area.jpg')
```

## Chlorophyll data {#methodschl}
Chlorophyll a concentration ([Chl]) data extracted from satellite remote-sensing databases based on measurements made with the Sea-viewing Wide Field of View Sensor (SeaWiFS), Moderate Resolution Imaging Spectroradiometer on the Aqua satellite (MODIS), Medium Resolution Imaging Spectrometer (MERIS), and Visible and Infrared Imaging/Radiometer Suite (VIIRS) sensors. We used the Garver, Siegel, Maritorena Model (GSM) merged data product at 100 km (equivalent to a 1° grid) and 8-day spatial and temporal resolutions, respectively, obtained from the 
[Hermes GlobColour website](www.hermes.acri.fr/index.php). These four sensors provide an overlapping time series of [Chl] during the period 1997 to 2018 and were combined based on a bio-optical model inversion algorithm (Maritorena et al. 2010). 

## Zooplankton abundance {#methodszoo}
Zooplankton abundance is measured by the Ecosystem Monitoring Program (EcoMon), which conducts shelf-wide bimonthly surveys of the NES ecosystem [@Kane2007]. Zooplankton and ichthyoplankton are collected throughout the water column to a maximum depth of 200 m using paired 61-cm Bongo samplers equipped with 333-micron mesh nets. Sample location in this survey is based on a randomized strata design, with strata defined by bathymetry and along-shelf location. Plankton taxa are sorted and identified. We used the bio-volume of the 18 most abundant taxonomic categories as potential predictor variables [(Table 2)](#fig:habitatdesc). The zooplankton sample time series has some missing values, which necessitated the removal of spring data for the years 1989, 1990, 1991, and 1994 and fall data for the years 1989, 1990, and 1992. The data for each seasonal time frame was interpolated to a complete field over the estimation grid using ordinary kriging. 

### {#fig:zooptab}

```{r zooptab, echo=F, message=FALSE, warnings=FALSE, results='asis'}
tabl <- "
|Variable name|Full name|
|:----------|:-----------|
|acarspp|*Acartia* spp. |
|calfin|*Calanus finmarchicus* |
|chaeto|*Chaetognatha*|
|cham|*Centropages hamatus* |
|cirr|*Cirripedia*|
|ctyp|*Centropages typicus* |
|echino|*Echinodermata*|
|evadnespp|*Evadne* spp.|
|gas|*Gastropoda*|
|hyper|*Hyperiidea*|
|larvaceans|*Appendicularians*|
|mlucens|*Metridia lucens* |
|oithspp|*Oithona* spp. |
|para|*Paracalanus* parvus |
|penilia|*Penilia* spp.|
|pseudo|*Pseudocalanus* spp. |
|salps|*Salpa*|
|tlong|*Temora longicornis*| 
"
df<-suppressWarnings(readr::read_delim(tabl, delim="|"))
df<-df[-c(1,2) ,c("Variable name","Full name")]
knitr::kable(
  df, booktabs = TRUE,
  caption = 'Variable and species names for the 18 most abundant zooplankton taxa in EcoMon survey data.'
)
```

## Occupancy models {#methodsocc}

Occupancy and productivity habitats for {{COMMON_NAME}} were estimated with random forest classification and regression models using a suite of static and dynamic predictor variables. Variation in species presence or absence and biomass across space, bathymetry factors, productivity factors, and climate factors were tested. Models were constructed separately for spring and fall seasons. The response variables were the occurrence and catch-per-unit-effort of {{COMMON_NAME}} in the Northeast Fisheries Science Center bottom trawl survey, which is a fishery-independent survey on the Northeast US Shelf. The survey is conducted in the spring and fall of the year and is based on a stratified random design, which provides both spatial and temporal depictions of fish and macroinvertebrate abundances [@Grosslein1969]. The independent or predictor variable set included physical environment variables, habitat descriptors, zooplankton variables, and remote sensing variables; the variables will be described in more detail below. Occupancy models were fit as two-factor classification models (absence as 0; presence as 1) using the randomForest R package [@randomForest].

Prior to fitting the model, the independent variable set was first tested for multi-collinearity among the predictors and correlated variables were eliminated (R package @rfUtilities-package, version 2.1-3). From this reduced set of predictors, the final model variables were selected utilizing the model selection criteria of [@Murphy2010] as implemented in rfUtilities. Productivity models were fit as regression models with log10 transformed biomass-per-unit-effort as the response variable and the same starting set of predictor variables as in the occupancy models. As with the occupancy models, independent variables were tested for multi-collinearity and the model selection criteria was applied. Habitat was estimated from the model fits over a standard 0.1° grid, which circumscribes the range of ecosystem assessment areas [in the region](#fig:study-area). 

Three types of visualizations were created from the output of the tree models. The first visualization was used to see the average probability of occupancy over space and the rate of change (Sen's slope) in occupancy over the years. The second visualization was used to see the mean occupancy gradient magnitude, or frontal strength and the rate of change (Sen's slope) in occupancy gradient magnitude over the years. Gradient magnitude was calculated by calculating the median of the occupancy probabilities with a moving window and then summing those medians with a moving window with a matrix of weights. The third visualization was used to see the average biomass over space and the rate of change (Sen's slope) in biomass over the years. Trends in total occupancy habitat area, with occupancy probabilities of 25, 50, and 75% over time were plotted as well by calculating the sum of the area with occupancy probabilities at each percentage during each year. 

### Predictor Variables
Static variables were kept constant over years where dynamic variables varied annually. Hence, the length of the time series of model fits is constrained by the shortest dynamic variable time series to meet the requirement of complete cases in the Random Forest fitting. The fitting time series was constrained to 1992 – 2016, which was determined by the length of the station salinity data. 

### Physical environment
Station data included observations made contemporaneously to survey bottom trawl stations. Depth of the station was used as a static variable in the analysis. The observed depth was used in model fitting where model predictions were based on depths from the ETOPO1 dataset, which provided Northeast Shelf bathymetry at a resolution of 0.0167° [(below)](#fig:occ_grid).

### {#fig:occ_grid}

```{r occ_grid, fig.align="center", fig.cap = "Estimation grid for predictor variable and habitat estimates, grid location spaced by 0.1° longitude and latitude.", echo = F, out.width=switch(knitr::opts_knit$get("rmarkdown.pandoc.to"), latex = "0.5\\linewidth", html = '500')}
knitr::include_graphics("data/images/ECSA_occ_grid.png")
```

Surface and bottom water temperature and salinity were used as dynamic variables in the analysis. Temperature and salinity on the NE Shelf was collected using Conductivity/Temperature/Depth (CTD) instruments with the most complete sample coverage associated with spring (February –April) and fall (September-November) time frames. Surface and bottom temperatures were used to develop date of collection corrections using linear regression for each time frame. Temperatures were standardized to a collection date of April 3 for spring collections and October 11 for fall. A date of collection correction was not indicated for salinity data. The observed date-corrected temperature (°C) and uncorrected salinity data (PSU) was used in model fitting. 

Model predictions were based on temperature and salinity fields using an optimal interpolation approach where annual data were combined with a climatology by season. For a half degree grid of the ecosystem, mean bottom temperature or salinity was calculated by year and season. For grid locations that had data for at least 80% of the time series, the data from those locals were used to calculate a seasonal mean. The annual seasonal means were used to calculate anomalies, which were combined over the time series to provide seasonal, surface and bottom anomaly climatologies. 

Returning to the raw data, the observations for a year, season, and depth were then used to estimate an annual field using universal kriging with depth as a covariate. The kriging was done on a standard 0.1° grid using the automap [@automap, version 1.0-14]. The annual field was then combined with the climatology anomaly field, adjusted by the annual mean, using the variance field from the kriging as the basis for a weighted mean between the two. The variance field was divided into quartiles with the first quartile (lowest kriging variance) carrying a weighting of 4:1 between the annual and climatology values. Hence, the optimal interpolated field at these locations were skewed towards the annual data reflecting their proximity to actual data locations and low kriging variance associated with them. The weighting ratio shifted to 1:1 in the highest variance quartile reflecting less information from the annual field and more from the climatology.

### Habitat Descriptors
Habitat descriptors are a series of static variables that reflect the shape and complexity of benthic habitats. Since the response variables for these models are derived from bottom trawl gear, naturally the range of candidate taxa for modelling is skewed to benthic organisms, making these descriptors particularly relevant. Most of the variables are based on depth measurement, including the complexity, BBI, VRM, Prcurv, rugostity, seabedforms, slp, and slpslp variables [(Table 1)](#fig:habitatdesc). The soft-sed variable is based on benthic sediment grain size and the vorticity variable is based on current estimates.

### Zooplankton Data
Zooplankton abundance is measured by the Ecosystem Monitoring Program (EcoMon), which conducts shelf-wide bimonthly surveys of the NES ecosystem [@Kane2007]. Zooplankton and ichthyoplankton are collected throughout the water column to a maximum depth of 200 m using paired 61-cm Bongo samplers equipped with 333-micron mesh nets. Sample location in this survey is based on a randomized strata design, with strata defined by bathymetry and along-shelf location. Plankton taxa are sorted and identified. We used the bio-volume of the 18 most abundant taxonomic categories as potential predictor variables [(Table 2)](#fig:habitatdesc). The zooplankton sample time series has some missing values which were ameliorated by summing data over five-year time steps for each seasonal time frame and interpolating a complete field using ordinary kriging. Thus, for example, the data for spring 2000 would include the available data from 1998-2002 tows. 

### Remote Sensing Data
Chlorophyll concentration and SST from remote sensing sources were applied in the habitat models as static variables. Chlorophyll and SST were summarized as monthly means with their associated gradient magnitude or frontal fields. The basis for the chlorophyll concentration was measurements made with the Sea-viewing Wide Field of View Sensor (SeaWiFS), Moderate Resolution Imaging Spectroradiometer on the Aqua satellite (MODIS), Medium Resolution Imaging Spectrometer (MERIS), and Visible and Infrared Imaging/Radiometer Suite (VIIRS) sensors during the period 1997-2016. The data is a merged product using the Garver, Siegel, Maritorena Model (GSM) algorithm obtained from the [Hermes GlobColour website](www.hermes.acri.fr/index.php). 

These four sensors provide an overlapping time series of chlorophyll concentration during the period and were combined based on a bio-optical model inversion algorithm (Maritorena et al. 2010). Monthly SST fields were based on data from the MODIS Terra sensor data available from the [Ocean Color Website](http://oceancolor.gsfc.nasa.gov/cms/). From these data, mean monthly fields were generated for both chlorophyll and SST. There are a range of methods used to identify fronts [@Belkin2009] in oceanographic data that usually apply some focal filter to reduce noise and identify gradient magnitude with a Sobel filter. These calculations were done in R using the raster package [@raster, version 2.6-7] using a 3 by 3 mean focal filter and a Sobel filter to generate x and y derivatives, which are then used to calculate gradient magnitude. 

### Model Selection Criteria and Variable Importance

The habitat models were evaluated for fit based on out-of-bag classification accuracy. For occupancy models accuracy, AUC (Area Under the ROC Curve), and Cohen’s Kappa were calculated using the irr R package [@irr, version 0.84]. For regression models, the variance explained by the model, mean absolute error, the root mean square error, and bias were calculated using the Metrics R package [@metrics, version 0.1.3]. To evaluate variable importance in both occupancy and regression models, we plotted the number of times a variable was the root variable versus the mean minimum node depth for the variable, highlighting the top ten important variables using the randomForestExplainer R package [@randomForestExplainer, version 0.9]. For occupancy models we also plotted the Gini index decrease versus accuracy decrease, whereas for the regression models we plotted node purity increase versus MSE increase, also highlighting the top ten most important variables. 

### {#fig:habitatdesc}

```{r habitatdesc, echo = F, results='asis', message=F, warning=F}
tab <- '
|Variables|Notes|References|
|:-----------------------|:-----------------------|:-----------------------|
|Complexity - Terrain Ruggedness Index|The difference in elevation values from a center cell and the eight cells immediately surrounding it. Each of the difference values are squared to make them all positive and averaged. The index is the square root of this average.|@Riley1999|
|Namera bpi|BPI is a second order derivative of the surface depth using the TNC Northwest Atlantic Marine Ecoregional Assessment ("NAMERA") data with an inner radius=5 and outer radius=50.|@Lundblad2006|
|Namera_vrm|Vector Ruggedness Measure (VRM) measures terrain ruggedness as the variation in three-dimensional orientation of grid cells within a neighborhood based the TNC Northwest Atlantic Marine Ecoregional Assessment ("NAMERA") data.|@Hobson1972; @Sappington2007|
|Prcurv (2 km, 10 km, and 20 km)|Benthic profile curvature at 2km, 10km and 20 km spatial scales was derived from depth data.|@Winship2018|
|Rugosity|A measure of small-scale variations of amplitude in the height of a surface, the ratio of the real to the geometric surface area.|@Friedman2012|
|seabedforms|Seabed topography as measured by a combination of seabed position and slope.|[http://www.northeastoceandata.org/]()|
|Slp (2 km, 10 km, and 20 km)|Benthic slope at 2km, 10km and 20km spatial scales.|@Winship2018|
|Slpslp (2 km, 10 km, and 20 km)|Benthic slope of slope at 2km, 10km and 20km spatial scales|@Winship2018|
|soft_sed|Soft-sediments is based on grain size distribution from the USGS usSeabed: Atlantic coast offshore surficial sediment data.|[http://www.northeastoceandata.org/]()|
|Vort (fall - fa; spring - sp; summer - su; winter - wi)|Benthic current vorticity at a 1/6 degree (approx. 19 km) spatial scale.|@Kinlan2016|
'
df<-readr::read_delim(tab, delim="|")
df<-df[-c(1,2,3) ,c("Variables","Notes","References")]
knitr::kable(
  df, booktabs = TRUE,
  caption = 'Habitat descriptors used in occupancy model parameterization.'
)
```

## Diet composition {#sec:methodsdiet}
NEFSC bottom-trawl sampling occurs twice annually in the spring (March-May) and fall (September-November). The survey area encompasses about 293,000 square km of continental shelf from Cape Hatteras, NC, to Nova Scotia, Canada in depths from 8-400 m. Food habits sampling has been conducted since 1973. 

Stomachs are collected at sea by NEFSC, and have been primarily analyzed at sea since 1981. Total stomach volume is estimated, each prey item is identified and sorted to the lowest possible taxonomic level, and the proportion of each prey item is estimated. Detailed methods are described in @link_overview_2000.
Prey composition percent by weight was calculated using a weighted mean ($\overline{W_{ijs}}$) [@link_overview_2000; @smith_trophic_2010] to estimate mean weight of prey $i$ in predator $j$ for statistical group $s$. Note: Prey volumes are used as proxies for prey weight. It may be calculated as

$$ \overline{W_{ijs}} = \frac{\sum_{t=1}^{N_{ts}}N_{jts}\overline{w_{ijts}}}{N_{ts}} $$

where $t$ represents an individual bottom trawl tow, $N_{jts}$ is the number of predator $j$ stomachs in tow $t$ for statistical group $s$, $N_{ts}$ is the number of tows in statistical group $s$, and
                
$$ \overline{w_{ijts}} = \frac{\sum_{k=1}^{N_{jts}}w_{ijtsk}}{N_{jts}} $$
            
## Appendix 

### Date of collection correction
The dates of survey data collection varied by year. To date correct temperature measurements, regressions were estimated between temperature and day of the year over the sample grid (0.5° grid) by season and depth. Spring data were transformed to a temperature representing April 3 and fall to October 11 based on the slope estimates shown in the maps in [Figure A1](#fig:doc_correction). 

### {#fig:doc_correction}

```{r doc_correction, fig.align = "center", echo = F, fig.width=6, fig.cap = "**Figure A1**: Spring (a) and fall (b) linear slope coefficients used to date correct surface temperature to standard spring and fall dates; same for spring (c) and fall (d) bottom temperature correction."}
par(mar=c(0,0,0,0), xpd=NA, mgp=c(0,0,0), oma=c(0,0,0,0), ann=F, mfrow = c(2,2))
a <-jpeg::readJPEG(here::here('data/images/ECSA_doc_correction_a.jpg'))
b <-jpeg::readJPEG(here::here('data/images/ECSA_doc_correction_b.jpg'))
c <-jpeg::readJPEG(here::here('data/images/ECSA_doc_correction_c.jpg'))
d <-jpeg::readJPEG(here::here('data/images/ECSA_doc_correction_d.jpg'))
plot.new()
usr<-par("usr")
 
#fill plot with images
rasterImage(a, usr[1], usr[3], usr[2], usr[4])
rasterImage(b, usr[1]+1.1, usr[3], usr[2]+1.1, usr[4])
rasterImage(c, usr[1], usr[3]-1.1, usr[2], usr[4]-1.1)
rasterImage(d, usr[1]+1.1, usr[3]-1.1, usr[2]+1.1, usr[4]-1.1)
```

<br>

### Cross validation performance of temperature interpolation
A series of random draws of training and test sets were taken to evaluate the predictive skill of the estimation procedure. A set of climatology, annual interpolation, or optimal interpolation fields were estimated using the training set and compared to the held-out test set. 

#### {#fig:cross_val}

```{r cross_val, fig.align="center", fig.cap = "**Figure A2**: Mean and 95% confidence intervals of squared errors for spring (a) and fall (b) surface temperature estimates based on climatology, annual interpolation, and optimal interpolation (OI); same data for spring (c) and fall (d) bottom temperature estimates.", echo = F}
knitr::include_graphics(here::here("data/images/ECSA_crossval_temp_oi.png"))
```

<br>

The distribution of errors from the optimal interpolation test sets were evaluated spatially to determine where the larger errors occurred and what ecosystem features they are associated with.

### {#fig:oi_mae}
```{r oi_mae, fig.align = "center", echo = F, fig.width=5.75, fig.cap = "**Figure A3**: Mean absolute error by 0.1 degree latitude and longitude intervals for spring (a) and fall (b) surface temperature; same data for spring (c) and fall (d) bottom temperature. Red indicates a positive error where blue indicates negative."}
par(mar=c(0,0,0,0), xpd=NA, mgp=c(0,0,0), oma=c(0,0,0,0), ann=F, mfrow = c(2,2))
a <-jpeg::readJPEG(here::here('data/images/ECSA_oi_error_dist_a.jpg'))
b <-jpeg::readJPEG(here::here('data/images/ECSA_oi_error_dist_b.jpg'))
c <-jpeg::readJPEG(here::here('data/images/ECSA_oi_error_dist_c.jpg'))
d <-jpeg::readJPEG(here::here('data/images/ECSA_oi_error_dist_d.jpg'))
plot.new()
usr<-par("usr")
 
#fill plot with images
rasterImage(a, usr[1], usr[3], usr[2], usr[4])
rasterImage(b, usr[1]+1.1, usr[3], usr[2]+1.1, usr[4])
rasterImage(c, usr[1], usr[3]-1.1, usr[2], usr[4]-1.1)
rasterImage(d, usr[1]+1.1, usr[3]-1.1, usr[2]+1.1, usr[4]-1.1)
```

<br>

### Comparisons to external data sources

Sea surface temperature estimated in this study were compared to the [OISST dataset](https://www.ncdc.noaa.gov/oisst) serving as a source of data for external comparison. The OISST data for April 3 (spring) and October 11 (fall) over the period 1982-2017 were extracted on the same 0.5° grid used in the study. Time series of matching spring and fall temperatures were differenced (external minus interpolation data) and presented in the figure below (sample size for surface spring and fall data were 5220 and 5365, respectively). The interquartile range for the surface comparisons were generally symmetric around zero with differences between 0.5-1°C. Bottom temperature estimated in this study were compared to the data from a cooperative data collection program for external comparison. The “Environmental Monitors on Lobster Traps” [(EMOLT)](http://comet.nefsc.noaa.gov/erddap/tabledap/eMOLT.html) is a cooperative research program that collects bottom temperatures. The data for spring and fall were extracted from rasters of the study data to match the extremal data. The external data covered the period 1968-2017, with 360 data points for the spring and 728 for the fall. Spring bottom comparisons yielded the smallest interquartile range of differences less than 0.5°C, where fall comparisons were slightly larger and biased to lower interpolation estimates compared to the external data.

### {#fig:oi_compare}

```{r oi_compare, fig.align="center", fig.cap = "**Figure A4**: Box plots (box: interquartile range, whisker: 5-95% range, square symbol: mean, line: median) of the difference between external and interpolation data.", echo = F}
knitr::include_graphics("data/images/ECSA_oi_compare.png")
```


## References


